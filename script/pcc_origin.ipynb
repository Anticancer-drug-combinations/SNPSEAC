{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adec8e86-80a9-492c-a297-32d4d11f09f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/jupyter-env/lib/python3.10/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re,math\n",
    "\n",
    "data1 = pd.read_excel(r'pcbi.1006752.s002.xlsx', sheet_name=\"Sheet1\",index_col='Drug').drop('SMILES',axis=1)\n",
    "data2 = pd.read_excel(r'583drugs39cell Zscore行标准化 synergy.xlsx')\n",
    "drug_names = list(data1.index)\n",
    "\n",
    "# # 合并drugA和drugB为一列作为索引\n",
    "# 顺序\n",
    "temp1 = [] # 分子指纹合并值 【【】，【】，【】，】\n",
    "index_1 = [] # 对应的名字列表 【【】，【】，【】，】\n",
    "# 逆序\n",
    "temp2 = []\n",
    "index_2 = []\n",
    "for index,row in data2.iterrows():\n",
    "    ct = list((np.array(data1.loc[row[\"DrugA\"],:])))\n",
    "    ct.extend(list((np.array(data1.loc[row[\"DrugB\"],:]))))\n",
    "    temp1.append(ct)\n",
    "    index_1.append((row[\"DrugA\"],row[\"DrugB\"]))\n",
    "    ct = list((np.array(data1.loc[row[\"DrugB\"],:])))\n",
    "    ct.extend(list((np.array(data1.loc[row[\"DrugA\"],:]))))\n",
    "    temp2.append(ct)\n",
    "    index_2.append((row[\"DrugB\"],row[\"DrugA\"]))\n",
    "\n",
    "# 两组数据的tanimoto计算\n",
    "def tanimoto(p,q):\n",
    "    tep1=0\n",
    "    tep2=0\n",
    "    lenthp=int(len(p))\n",
    "    for i in range(lenthp):\n",
    "        a=p[i]\n",
    "        b=q[i]\n",
    "        if (a==1)|(b==1): # 并\n",
    "            tep1=tep1+1\n",
    "        if (a==1)&(b==1): # 交\n",
    "            tep2=tep2+1\n",
    "    c=round((tep2 / tep1),4)      #取值4位数\n",
    "    return c\n",
    "\n",
    "# 相互之间做一次tanimoto\n",
    "temp=[]\n",
    "Tanimoto_index_dist = {} # {顺序药物对：(实际药物名字1，实际药物名字2，值)}\n",
    "for i,j,i_n,j_n in zip(temp1,temp2,index_1,index_2):\n",
    "    tmp=[]\n",
    "    a = np.array(i) #取出一分子指纹 转换列表为向量\n",
    "    b = np.array(j)\n",
    "    for k,m,k_n,m_n in zip(temp1,temp2,index_1,index_2): # 遍历每一个药物对的分子指纹\n",
    "        c = np.array(k)\n",
    "        d = np.array(m)\n",
    "        tp1 = tanimoto(a,c)\n",
    "        tp2 = tanimoto(a,d)\n",
    "        tp3 = tanimoto(b,c)\n",
    "        tp4 = tanimoto(b,d)\n",
    "        tps = [tp1, tp2, tp3, tp4]\n",
    "        index_list = [(i_n,k_n,tp1),(i_n,m_n,tp2),(j_n,k_n,tp3),(j_n,m_n,tp4)]\n",
    "        index_location = tps.index(max(tps))\n",
    "        tmp.append(max(tps))\n",
    "        Tanimoto_index_dist[f\"{i_n},{k_n}\"] = index_list[index_location]\n",
    "    temp.append(tmp)\n",
    "Tanimoto=pd.DataFrame(temp,columns=index_1,index=index_1) # 数据框 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2a27025-7dd0-4ccf-9dce-e183ec8eca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tanimoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ead6ee-a725-4ede-9d24-a7f94af38a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 获取栏目数组\n",
    "ttpp = []\n",
    "for i in list(Tanimoto.columns):\n",
    "    ttpp.append(str(i)[1:-1]) # 去除首尾括号的药物对名字\n",
    "data2 = pd.DataFrame(data2.iloc[:,2:].T.values, columns=list(ttpp)) # 药物对协同得分\n",
    "columns = data2.columns # 修改后的药物对名字\n",
    "\n",
    "\n",
    "# 删去对应行后的字典\n",
    "dict_lines = {} # {键1：值1} 谷本系数字典\n",
    "count = 0\n",
    "ct = 0\n",
    "for i in Tanimoto.index:\n",
    "    y = list(Tanimoto.iloc[:,ct]) # 每一列谷本系数 [:,1] 第一列的每一行 实际就是第一列\n",
    "    y.pop(count)\n",
    "    count += 1\n",
    "    dict_lines[columns[ct]] = y # 谷本系数药物对的名字做键1，y是值1\n",
    "    ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00c3aebd-3c86-4cf2-ad91-a32f73f42b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高相似多少\n",
    "coum=5\n",
    "\n",
    "# 分离x y数据构造字典\n",
    "dict_columns = {}  # {a1:data,a2:data} 药物对名字-对应数据\n",
    "for i in columns:\n",
    "\n",
    "    # b 要预测协同得分那一列\n",
    "    y = data2.loc[:, i]\n",
    "\n",
    "    # A 权重\n",
    "    temp = []\n",
    "    for j in columns:\n",
    "        if j != i:\n",
    "            temp.append(j)\n",
    "    m = data2.loc[:, temp[0]]\n",
    "    tp = [m]\n",
    "    for j in temp[1:]:\n",
    "        tp.append(data2.loc[:, j])\n",
    "    x = pd.DataFrame(tp).T  # 其他所有的列\n",
    "\n",
    "    # 高相似的    取高相似的药物对名字max1和对应的值max5\n",
    "    tp = []\n",
    "    for j in columns:\n",
    "        if i != j:\n",
    "            tp.append(j)\n",
    "    df = pd.DataFrame(dict_lines[i], index=tp)\n",
    "    df.sort_values(by=0, inplace=True, ascending=True)  # 从低到高排序\n",
    "    max_l = df.index[-coum:]  # 倒着取高相似的5个的名字 排序还是从低到高\n",
    "    tp = []\n",
    "    for j in max_l:\n",
    "        tp.append(data2.loc[:, j])\n",
    "    max_5x = pd.DataFrame(tp).T  # 值\n",
    "\n",
    "    # 存储 对应数据\n",
    "    data = {\n",
    "        \"x\": x,  # 其他所有的列 数据表，含药物对名字\n",
    "        \"y\": y,  # 要预测协同得分的那一列 含药物对名字\n",
    "        # 下面两个是对应的\n",
    "        \"max_relevance\": max_l,  # 高相似名字\n",
    "        \"max_5x\": max_5x  # 前多少高相似邻居对应的列\n",
    "    }\n",
    "    dict_columns[i] = data\n",
    "\n",
    "dict_columns_split = {} # 高相似字典\n",
    "for i in dict_columns: # 第几列 i 是药物对名字\n",
    "    count = 0 # 第几行 int\n",
    "    for j in list(dict_columns[i]['y'].index): # 35个索引 0~34 数字（字符串-str） 【0，1，2，3.。。。】\n",
    "        dict_columns_split[f'{i},{j}']={} # 空字典 键-空字典\n",
    "        dict_columns_split[f'{i},{j}']['y_line']=dict_columns[i][\"y\"][count]\n",
    "        dict_columns_split[f'{i},{j}']['max_x_line']=dict_columns[i][\"max_5x\"].iloc[count,:].values\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b046269-629a-4ef8-8c1d-6f7a9e1ad864",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14583069,  0.17624582,  0.40102622, -0.4231079 ,  0.06873453])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_columns_split[\"'SUNITINIB', 'MK-4827',32\"]['max_x_line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "393b5ed5-0760-498c-857c-76a664d57278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高相似谷本系数字典 (删去对应行后的字典)\n",
    "dict_high_lines = {} \n",
    "count = 0\n",
    "cct = 0\n",
    "for i in Tanimoto.index: # 循环遍历谷本系数名字\n",
    "    y = list(Tanimoto.iloc[:,cct])\n",
    "    y.pop(count) # 去除相同药物对的谷本系数\n",
    "    count += 1\n",
    "    dict_high_lines[str(i)[1:-1]] = y # 去除药物对首尾括号做键，去除后剩余的谷本系数列做值\n",
    "\n",
    "    tp = []\n",
    "    for j in columns: #来源于协同得分名字和来源于谷本系数名字比较，不同的就存储\n",
    "        if str(i)[1:-1] != j:\n",
    "            tp.append(j)\n",
    "    df = pd.DataFrame(dict_high_lines[str(i)[1:-1]], index=tp) # 除去1的数据框 582*1\n",
    "    df.sort_values(by=0 , inplace=True, ascending=True) # 排序 低到高\n",
    "\n",
    "    max_l = df.index[-coum:]  # 取最后5高相似\n",
    "    tp = [] # 5个名字对应列的值\n",
    "    for j in max_l:\n",
    "        tp.append(Tanimoto.iloc[list(columns).index(j), :])\n",
    "    max_5y = list(pd.DataFrame(tp).T.iloc[[list(columns).index(str(i)[1:-1])]].values)[0]\n",
    "\n",
    "    data = {\n",
    "        \"y\": y,\n",
    "        \"max_relevance\": max_l,\n",
    "        \"high_5\": max_5y\n",
    "    }\n",
    "    dict_high_lines[str(i)[1:-1]] = data\n",
    "    cct += 1\n",
    "\n",
    "dict_high_lines_split = {}\n",
    "for i in dict_high_lines: # i 是目标药物对名字\n",
    "    count = 0\n",
    "    for j in dict_high_lines[i]['max_relevance']: # 遍历高相似的名字\n",
    "        dict_high_lines_split[f'{i},{j}']=dict_high_lines[i]['high_5'][count]\n",
    "        count += 1\n",
    "\n",
    "\n",
    "TTT = [] # 值列表\n",
    "for i in dict_high_lines_split:\n",
    "    TTT.append(dict_high_lines_split[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a171fd3e-60c2-467c-be3c-a1226ca95add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTT[-210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "66f89c84-dbff-4e17-a64d-dfa9b82d6832",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#print(TTT[70-10:70])\n",
    "\n",
    "Name = []\n",
    "a = 1\n",
    "# 加载保存的数组\n",
    "lin = np.load(\"lin.npy\")\n",
    "for linename in columns:\n",
    "    PCC = 0\n",
    "    Name_data = []\n",
    "    for t_coum in range(2, coum+1, 1):    #邻居\n",
    "        #求PCC\n",
    "        alpha = []\n",
    "        result_pcc = []\n",
    "        pcc_split = []\n",
    "        for alp in lin:\n",
    "            # r1 = []\n",
    "            # ct = 0\n",
    "            pre = []\n",
    "            for elem in range(39):\n",
    "                pp = []\n",
    "                for j in TTT[(coum * a - t_coum):(coum * a)]: \n",
    "                    pp.append(np.exp(-pow(1 - j, 2) / (2 * pow(alp, 2))))#改函数\n",
    "                pre.append(np.sum(pp / np.sum(pp) * dict_columns_split[f\"{linename},{elem}\"]['max_x_line'][-t_coum:]))\n",
    "            pcc_split.append(np.corrcoef(pre, data2[linename])[0, 1])\n",
    "        result_pcc.append(np.max(pcc_split))\n",
    "        alpha.append(lin[pcc_split.index(np.max(pcc_split))])\n",
    "        pcc=result_pcc[0]\n",
    "\n",
    "        #求MSE\n",
    "        #pre = []\n",
    "        r1 = []\n",
    "        ct = 0\n",
    "        alp = alpha[0]\n",
    "        for elem in range(39):\n",
    "            pp = []\n",
    "            for j in TTT[(coum * a - t_coum):(coum * a)]: # dict_high_lines_split 里一组的数量是80\n",
    "                pp.append(np.exp(-pow(1 - j, 2) / (2 * pow(alp, 2))))  # 改函数\n",
    "            r1.append(np.sum((pp/np.sum(pp)) * dict_columns_split[f\"{linename},{elem}\"]['max_x_line'][-t_coum:]) -\n",
    "                            dict_columns_split[f\"{linename},{elem}\"]['y_line'])\n",
    "        mse=np.mean(np.square(r1))\n",
    "        rmse=math.sqrt(mse)\n",
    "        if pcc > PCC:\n",
    "            Name_coum, Name_mse, Name_pcc, Name_alp, PCC, Name_rmse = t_coum, mse, pcc, alp, pcc, rmse\n",
    "        elif PCC == 0:\n",
    "            Name_coum, Name_mse, Name_pcc, Name_alp, PCC, Name_rmse = t_coum, mse, pcc, alp, pcc, rmse\n",
    "        if t_coum == coum:\n",
    "            Name_data.append(linename)\n",
    "            Name_data.append(Name_coum)\n",
    "            Name_data.append(Name_alp)\n",
    "            Name_data.append(Name_mse)\n",
    "            Name_data.append(Name_pcc)\n",
    "            Name_data.append(Name_rmse)\n",
    "    a = a+1\n",
    "    Name.append(Name_data)\n",
    "pd.DataFrame(Name).to_csv('pcc_origin.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98100ce4-bf09-4b97-8fc4-d9eb07690751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78effeb-09f3-4fb6-9d53-309f3276af49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fd7f47-8495-4b2c-8a0b-3b6b5578406b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
