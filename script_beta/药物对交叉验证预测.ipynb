{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re,math\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data1 = pd.read_excel(r'pcbi.1006752.s002.xlsx', sheet_name=\"Sheet1\",index_col='Drug').drop('SMILES',axis=1)\n",
    "data2 = pd.read_excel(r'Label_synergy4000.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = []\n",
    "index_l = []\n",
    "for index,row in data2.iterrows():\n",
    "    ct = np.array(data1.loc[row[\"DrugA\"],:]) + np.array(data1.loc[row[\"DrugB\"],:])\n",
    "    tp = []\n",
    "    for i in ct:\n",
    "        if i >= 1:\n",
    "            tp.append(1)\n",
    "        else:\n",
    "            tp.append(0)\n",
    "    temp1.append(tp)\n",
    "    index_l.append((row[\"DrugA\"],row[\"DrugB\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tanimoto(p,q):\n",
    "    tep1=0\n",
    "    tep2=0\n",
    "    lenthp=int(len(p))\n",
    "    for i in range(lenthp):\n",
    "        a=p[i]        \n",
    "        b=q[i]\n",
    "        if (a==1)|(b==1):\n",
    "            tep1=tep1+1\n",
    "        if (a==1)&(b==1):\n",
    "            tep2=tep2+1 \n",
    "    c=float(tep2 / tep1)        \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=[]  \n",
    "for i in temp1:\n",
    "    tmp=[]   \n",
    "    a=np.array(i)\n",
    "    for j in temp1:\n",
    "        b=np.array(j)\n",
    "        tp=tanimoto(a,b)\n",
    "        tmp.append(tp)\n",
    "    temp.append(tmp)\n",
    "Tanimoto=pd.DataFrame(temp,columns=index_l,index=index_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttpp = []\n",
    "for i in list(Tanimoto.columns):\n",
    "    ttpp.append(str(i)[1:-1])\n",
    "data2 = pd.DataFrame(data2.iloc[:,2:].T.values, columns=list(ttpp))\n",
    "columns = data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删去对应行后的字典\n",
    "dict_lines = {}\n",
    "count = 0\n",
    "ct = 0\n",
    "for i in Tanimoto.index:\n",
    "    y = list(Tanimoto.iloc[:,ct])\n",
    "    y.pop(count)\n",
    "    count += 1\n",
    "    dict_lines[columns[ct]] = y\n",
    "    ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分离x y数据构造字典\n",
    "dict_columns = {}\n",
    "for i in columns: \n",
    "    \n",
    "    # b\n",
    "    y = data2.loc[:,i]\n",
    "    \n",
    "    # A\n",
    "    temp = []\n",
    "    for j in columns:\n",
    "        if j != i:\n",
    "            temp.append(j)\n",
    "    m = data2.loc[:, temp[0]]\n",
    "    tp = [m]\n",
    "    for j in temp[1:]:\n",
    "        tp.append(data2.loc[:, j])\n",
    "    x = pd.DataFrame(tp).T\n",
    "    \n",
    "    tp = []\n",
    "    for j in columns:\n",
    "        if i != j:\n",
    "            tp.append(j)\n",
    "    df = pd.DataFrame(dict_lines[i], index=tp)\n",
    "    df.sort_values(by=0 , inplace=True, ascending=True)\n",
    "    max_l = df.index[-5:]\n",
    "    tp = []\n",
    "    for j in max_l:\n",
    "        tp.append(data2.loc[:, j])\n",
    "    max_5x = pd.DataFrame(tp).T\n",
    "    \n",
    "    # 存储\n",
    "    data = {\n",
    "        \"x\": x,\n",
    "        \"y\": y,\n",
    "        \"max_relevance\": max_l,\n",
    "        \"max_5x\": max_5x\n",
    "    }\n",
    "    dict_columns[i] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 删去对应行后的字典\n",
    "dict_high_lines = {}\n",
    "count = 0\n",
    "cct = 0\n",
    "for i in Tanimoto.index:\n",
    "    y = list(Tanimoto.iloc[:,cct])\n",
    "    y.pop(count)\n",
    "    count += 1\n",
    "    dict_high_lines[str(i)[1:-1]] = y\n",
    "    tp = []\n",
    "    for j in columns:\n",
    "        if str(i)[1:-1] != j:\n",
    "            tp.append(j)\n",
    "    df = pd.DataFrame(dict_high_lines[str(i)[1:-1]], index=tp)\n",
    "    df.sort_values(by=0 , inplace=True, ascending=True)\n",
    "    max_l = df.index[-5:] \n",
    "    tp = []\n",
    "    for j in max_l:\n",
    "        tp.append(Tanimoto.iloc[list(columns).index(j), :])\n",
    "    max_5y = list(pd.DataFrame(tp).T.iloc[[list(columns).index(str(i)[1:-1])]].values)[0]\n",
    "    data = {\n",
    "        \"y\": y,\n",
    "        \"max_relevance\": max_l,\n",
    "        \"high_5\": max_5y\n",
    "    }\n",
    "    dict_high_lines[str(i)[1:-1]] = data\n",
    "    cct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "end_score = []\n",
    "name_dict_high_lines = []\n",
    "for elem in dict_high_lines:\n",
    "    end_score.append(dict_high_lines[elem]['high_5'].mean())\n",
    "    name_dict_high_lines.append(elem)\n",
    "dict_high_lines_temp = {}\n",
    "for score in end_score:\n",
    "    if score >= 0.90:\n",
    "        dict_high_lines_temp[name_dict_high_lines[end_score.index(score)]] = dict_high_lines[name_dict_high_lines[end_score.index(score)]]\n",
    "print(len(dict_high_lines_temp))\n",
    "dict_high_lines = dict_high_lines_temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictW(alpha):\n",
    "    # 运算构造参数W字典 \n",
    "    dict_W = {}\n",
    "    for elem in dict_high_lines:\n",
    "        r = np.array(dict_high_lines[elem][\"high_5\"])\n",
    "        W1= pow((1-r),2)\n",
    "        W = np.exp(-W1/(2*pow(alpha,2)))\n",
    "        dict_W[elem] = W\n",
    "    return dict_W\n",
    "\n",
    "#计算MSE\n",
    "def dictr(dict_W):\n",
    "# 残差字典 \n",
    "    # r = max(|A×W - b|)\n",
    "    dict_r = {}\n",
    "    dict_r_list = {}\n",
    "    for elem,w in zip(dict_columns, dict_W):\n",
    "        A = np.array(dict_columns[elem][\"max_5x\"].values) # x----->max_5x\n",
    "        b = np.array(dict_columns[elem][\"y\"].values)\n",
    "        W = dict_W[w]\n",
    "        temp1 = np.dot(A,W) - b\n",
    "        temp2 = np.square(temp1)\n",
    "        temp3 = np.mean(temp2)\n",
    "        dict_r[w] = temp3\n",
    "    return dict_r\n",
    "\n",
    "def dirlist(dict_r):\n",
    "    #计算RMSE  \n",
    "    dir_list = []\n",
    "    for elem in dict_r:\n",
    "        dir_list.append(np.sqrt(dict_r[elem]));\n",
    "    return dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev=100\n",
    "lin=np.linspace(0.001,1,1000)\n",
    "for alpha in lin:\n",
    "    \n",
    "    dict_W = dictW(alpha)\n",
    "    \n",
    "    dict_r = dictr(dict_W)\n",
    "\n",
    "    dir_list=dirlist(dict_r)\n",
    "    \n",
    "    temp=np.mean(dir_list)\n",
    "                      \n",
    "    #误差判断\n",
    "    if(temp>=dev):\n",
    "        continue\n",
    "    else:\n",
    "        dev=temp\n",
    "        al=alpha\n",
    "\n",
    "alpha=al\n",
    "dict_W = dictW(alpha)\n",
    "dict_r= dictr(dict_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.041"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429.4291309882982"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(dict_r.values())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('药物对.pkl', 'wb') as file:\n",
    "    pickle.dump(dict_W, file)\n",
    "    pickle.dump(dict_columns, file)\n",
    "    pickle.dump(dict_high_lines, file) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
