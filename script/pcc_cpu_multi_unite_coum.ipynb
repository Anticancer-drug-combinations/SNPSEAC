{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8273a9cf-73ba-4b3a-a705-17be586cea36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/jupyter-env/lib/python3.10/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re,math\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "import threading\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# 设置日志级别\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# 设置函数运行计时用的修饰器\n",
    "def timeit(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        print(f'{func.__name__} took {end - start:.6f} seconds')\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# 高相似多少\n",
    "coum=5\n",
    "# 加载保存的数组\n",
    "lin = np.load(\"lin.npy\")\n",
    "# lin = np.linspace(0,3,401)\n",
    "# lin = np.linspace(0.01,1,100)\n",
    "\n",
    "\n",
    "data1 = pd.read_excel(r'pcbi.1006752.s002.xlsx', sheet_name=\"Sheet1\",index_col='Drug').drop('SMILES',axis=1)\n",
    "data2 = pd.read_excel(r'583drugs39cell Zscore行标准化 synergy.xlsx')\n",
    "cells_name = pd.read_excel(r'583drugs39cell Zscore行标准化 synergy.xlsx', header=0).columns[2:] # 保证cells的名字从第一行的第三个开始\n",
    "drug_names = list(data1.index)\n",
    "\n",
    "# 合并drugA和drugB为一列作为索引\n",
    "# 顺序\n",
    "temp1 = [] # 分子指纹合并值 【【】，【】，【】，】\n",
    "index_1 = [] # 对应的名字列表 【【】，【】，【】，】\n",
    "# 逆序\n",
    "temp2 = []\n",
    "index_2 = []\n",
    "for index,row in data2.iterrows():\n",
    "    ct = list((np.array(data1.loc[row[\"DrugA\"],:])))\n",
    "    ct.extend(list((np.array(data1.loc[row[\"DrugB\"],:]))))\n",
    "    temp1.append(ct)\n",
    "    index_1.append((row[\"DrugA\"],row[\"DrugB\"]))\n",
    "    ct = list((np.array(data1.loc[row[\"DrugB\"],:])))\n",
    "    ct.extend(list((np.array(data1.loc[row[\"DrugA\"],:]))))\n",
    "    temp2.append(ct)\n",
    "    index_2.append((row[\"DrugB\"],row[\"DrugA\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2434a01-e7f7-45f3-8c0a-e9afc83e2cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 两组数据的tanimoto计算\n",
    "def tanimoto(p,q):\n",
    "    tep1=0\n",
    "    tep2=0\n",
    "    lenthp=int(len(p))\n",
    "    for i in range(lenthp):\n",
    "        a=p[i]\n",
    "        b=q[i]\n",
    "        if (a==1)|(b==1): # 并\n",
    "            tep1=tep1+1\n",
    "        if (a==1)&(b==1): # 交\n",
    "            tep2=tep2+1\n",
    "    c=round((tep2 / tep1),4)      #取值4位数\n",
    "    return c\n",
    "\n",
    "def compute_tanimoto(i, j, i_n, j_n, temp1, temp2, index_1, index_2, idx):\n",
    "    tmp=[]\n",
    "    a = np.array(i) #取出一分子指纹 转换列表为向量\n",
    "    b = np.array(j)\n",
    "    for k,m,k_n,m_n in zip(temp1,temp2,index_1,index_2): # 遍历每一个药物对的分子指纹\n",
    "        c = np.array(k)\n",
    "        d = np.array(m)\n",
    "        tp1 = tanimoto(a,c)\n",
    "        tp2 = tanimoto(a,d)\n",
    "        tp3 = tanimoto(b,c)\n",
    "        tp4 = tanimoto(b,d)\n",
    "        tps = [tp1, tp2, tp3, tp4]\n",
    "        index_list = [(i_n,k_n,tp1),(i_n,m_n,tp2),(j_n,k_n,tp3),(j_n,m_n,tp4)]\n",
    "        index_location = tps.index(max(tps))\n",
    "        tmp.append(max(tps))\n",
    "        Tanimoto_index_dist[f\"{i_n},{k_n}\"] = index_list[index_location]\n",
    "    return idx, tmp\n",
    "\n",
    "temp = [None] * len(temp1)\n",
    "Tanimoto_index_dist = {}\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # 提交任务时使用 enumerate ，并将索引值作为参数传递给任务函数\n",
    "    futures = [executor.submit(compute_tanimoto, i, j, i_n, j_n, temp1, temp2, index_1, index_2, idx)\n",
    "               for idx, (i,j,i_n,j_n) in enumerate(zip(temp1,temp2,index_1,index_2))]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        idx, result = future.result()\n",
    "        temp[idx] = result\n",
    "Tanimoto = pd.DataFrame(temp, columns=index_1, index=index_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fbe1ea7-6420-400f-b063-3ecac6608a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取columns数组 - 处理后的\n",
    "ttpp = []\n",
    "for i in list(Tanimoto.columns):\n",
    "    ttpp.append(str(i)[1:-1]) # 去除首尾括号的药物对名字\n",
    "data2 = pd.DataFrame(data2.iloc[:,2:].T.values, columns=list(ttpp)) # 药物对协同得分\n",
    "columns = data2.columns # 修改后的药物对名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2de4fcb-3f8f-4738-8dff-ebc14e3b5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删去对应行后的字典\n",
    "dict_lines = {} # {键1：值1} 谷本系数字典\n",
    "count = 0\n",
    "ct = 0\n",
    "for i in Tanimoto.index:\n",
    "    y = list(Tanimoto.iloc[:,ct]) # 每一列谷本系数 [:,1] 第一列的每一行 实际就是第一列\n",
    "    y.pop(count)\n",
    "    count += 1\n",
    "    dict_lines[columns[ct]] = y # 谷本系数药物对的名字做键1，y是值1\n",
    "    ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc9da7db-2376-42e0-ac82-d2dfaf3a5141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分离x y数据构造字典\n",
    "dict_columns_split = {} # 高相似字典\n",
    "# 计算x数据\n",
    "x = data2.drop(columns=columns)  # 其他所有的列\n",
    "for i in columns:\n",
    "    # b 要预测协同得分那一列\n",
    "    y = data2.loc[:, i]\n",
    "    # A 权重\n",
    "    x_i = x.copy()\n",
    "    x_i['y'] = y\n",
    "\n",
    "    # 高相似的    取高相似的药物对名字max1和对应的值max5\n",
    "    tp = []\n",
    "    for j in columns:\n",
    "        if i != j:\n",
    "            tp.append(j)\n",
    "    df = pd.DataFrame(dict_lines[i], index = tp)\n",
    "    df.sort_values(by=0, inplace=True, ascending=True)\n",
    "    max_l = df.index[-coum:]\n",
    "    max_5x = pd.DataFrame([data2.loc[:, j] for j in max_l]).T\n",
    "\n",
    "    # 存储 对应数据\n",
    "    count = 0 # 第几行 int\n",
    "    for j in list(y.index): # 35个索引 0~34 数字（字符串-str） 【0，1，2，3.。。。】\n",
    "        dict_columns_split[f'{i},{j}']={} # 空字典 键-空字典\n",
    "        dict_columns_split[f'{i},{j}']['y_line']=y[count]\n",
    "        dict_columns_split[f'{i},{j}']['max_x_line']=max_5x.iloc[count,:].values\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9fc797bb-93c1-49a9-9dee-5775a00fd7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14583069,  0.17624582,  0.40102622, -0.4231079 ,  0.06873453])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_columns_split[\"'SUNITINIB', 'MK-4827',32\"]['max_x_line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d02d146-3b56-48ce-b0e6-99dc9e1a1a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "TTT = [] # 值列表\n",
    "cct = 0\n",
    "NNN = []\n",
    "for i in Tanimoto.index: \n",
    "    y = list(Tanimoto.iloc[:,cct])\n",
    "    y.pop(cct) \n",
    "    tp_columns = list(columns.copy())\n",
    "    tp_columns.pop(cct)\n",
    "    df = pd.DataFrame(y, index=tp_columns)\n",
    "    df.sort_values(by=0 , inplace=True, ascending=True) \n",
    "    max_l = df.index[-coum:]\n",
    "    NNN.extend(max_l)\n",
    "    # 计算max_5y\n",
    "    max_5y = []\n",
    "    for j in max_l:\n",
    "        max_5y.append(Tanimoto.iloc[list(columns).index(j), cct])\n",
    "    # 将max_5y加入TTT\n",
    "    TTT += max_5y\n",
    "    # 修改cct变量的值\n",
    "    cct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aab7f251-5c05-4e7d-aa8c-cdda8d1a56cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_pcc(t_coum, a, lin, linename, dict_columns_split, TTT, coum, data2, NNN):\n",
    "    alpha = []\n",
    "    result_pcc = []\n",
    "    pcc_split = []\n",
    "    pre_dict = []\n",
    "    ori_dict = []\n",
    "    for alp in lin:\n",
    "        pre = []\n",
    "        for elem in range(39):\n",
    "            pp = [] \n",
    "            if TTT[(coum * a - t_coum):(coum * a)] == []:\n",
    "                print(\"ERROR-TTT\")\n",
    "            for j in TTT[(coum * a - t_coum):(coum * a)]: \n",
    "                pp.append(np.exp(-pow(1 - j, 2) / (2 * pow(alp, 2))))\n",
    "            pp = np.array(pp)  # 将 pp 转换为 numpy 数组\n",
    "            pre.append(np.sum(pp / np.sum(pp) * dict_columns_split[f\"{linename},{elem}\"]['max_x_line'][-t_coum:]))\n",
    "        pre = np.array(pre)  # 将 pre 转换为 numpy 数组\n",
    "        pre_dict.append(pre)\n",
    "        ori_dict.append(data2[linename])\n",
    "        pcc_split.append(np.corrcoef(pre, data2[linename])[0, 1])\n",
    "    result_pcc.append(np.max(pcc_split))\n",
    "    alpha.append(lin[pcc_split.index(np.max(pcc_split))])\n",
    "    pre = pre_dict[pcc_split.index(np.max(pcc_split))]\n",
    "    ori = ori_dict[pcc_split.index(np.max(pcc_split))]\n",
    "    pcc=result_pcc[0]\n",
    "    temp_NNN = NNN[(coum * a - t_coum):(coum * a)]\n",
    "    temp_TTT = TTT[(coum * a - t_coum):(coum * a)]\n",
    "    del result_pcc, pcc_split, pp\n",
    "    return alpha, pcc, temp_NNN, temp_TTT, pre, ori\n",
    "\n",
    "def alp_mse_rmse(alpha, t_coum, a, linename, dict_columns_split, TTT, coum):\n",
    "    r1 = []  # 初始化 r1 为空列表\n",
    "    alp = alpha[0]\n",
    "    for elem in range(39):\n",
    "        pp = []\n",
    "        for j in TTT[(coum * a - t_coum):(coum * a)]: \n",
    "            try:\n",
    "                pp.append(np.exp(-pow(1 - j, 2) / (2 * pow(alp, 2))))  \n",
    "            except:\n",
    "                print(linename)\n",
    "        r1.append(np.sum((pp/np.sum(pp)) * dict_columns_split[f\"{linename},{elem}\"]['max_x_line'][-t_coum:]) - dict_columns_split[f\"{linename},{elem}\"]['y_line'])\n",
    "    r1 = np.array(r1)  # 将 r1 转换为 numpy 数组\n",
    "    mse = np.mean(np.square(r1))\n",
    "    rmse = math.sqrt(mse)\n",
    "    del r1, pp,\n",
    "    return alp, mse, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3adbf05-9b09-4e1b-a972-dd5db55f6aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 单进程 分函数\n",
    "def calculate_parameters(t_coum, coum, TTT, data2, dict_columns_split, lin, NNN):\n",
    "    a = 1\n",
    "    Name_data = []\n",
    "    temp_NNN_list, temp_TTT_list, pre_list, ori_list = [], [], [], []\n",
    "    for linename in columns:  \n",
    "        # 求PCC\n",
    "        alpha, pcc, temp_NNN, temp_TTT, pre, ori = alpha_pcc(t_coum, a, lin, linename, dict_columns_split, TTT, coum, data2, NNN)\n",
    "        # 求MSE\n",
    "        alp, mse, rmse = alp_mse_rmse(alpha, t_coum, a, linename, dict_columns_split, TTT, coum)\n",
    "        Name_data.append([linename, t_coum, alp, mse, pcc, rmse])\n",
    "        temp_NNN_list.append(temp_NNN)\n",
    "        temp_TTT_list.append(temp_TTT)\n",
    "        pre_list.append(pre)\n",
    "        ori_list.append(ori)\n",
    "        a = a+1\n",
    "    pcc_mean = pd.DataFrame(Name_data, columns=['drug', 'coum', \"alp\", \"mse\", \"pcc\", \"rmse\"])[\"pcc\"].mean()\n",
    "    print(pcc_mean)\n",
    "    return [pcc_mean, Name_data, temp_NNN_list, temp_TTT_list, pre_list, ori_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1848158c-e4a9-4f6b-ad8f-49910f3d7bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3134730948109902\n",
      "0.3508114189090811\n",
      "0.33450193291801794\n",
      "0.35616993203738073\n",
      "run_parallel took 22.469946 seconds\n",
      "MAX PCC:  0.35616993203738073\n"
     ]
    }
   ],
   "source": [
    "# 多进程\n",
    "@timeit\n",
    "def run_parallel(columns, lin,NNN):\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        tp = []\n",
    "        for t_coum in range(2, coum+1, 1):\n",
    "            tp.append((t_coum, coum, TTT, data2, dict_columns_split, lin, NNN,))\n",
    "        results = pool.starmap(calculate_parameters, tp)\n",
    "    return results\n",
    "\n",
    "PCC_mean = 0\n",
    "res_pcc_list = []\n",
    "results = run_parallel(columns,lin,NNN)\n",
    "sorted_list = sorted(results, key=lambda x: x[0])\n",
    "max_res = sorted_list[-1][1]\n",
    "print(\"MAX PCC: \", sorted_list[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a2d8fd1-f930-48ca-82e5-3595664acd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将结果保存到 CSV 文件中\n",
    "pd.DataFrame(max_res).to_csv('pcc_cpu_test_multi_unite_coum.csv', header=None, index=False)\n",
    "rebuild_list = []\n",
    "for i,j,k in zip(max_res, sorted_list[-1][2], sorted_list[-1][3]):\n",
    "        for q,l in zip(j,k):\n",
    "            rebuild_list.append([q,i[0],l,i[1],i[2],i[4],i[5]])\n",
    "pd.DataFrame(rebuild_list,columns=[\"target_neighbor\",\"target\",\"similarity\",\"neighbors\",\"alp\",\"pcc\",\"rmse\"]).to_csv(\"pcc_cpu_test_multi_target_unite_coum.csv\")\n",
    "temp_list = []\n",
    "for i,j,k in zip(max_res, sorted_list[-1][4], sorted_list[-1][5]):\n",
    "        for m,q,l in zip(cells_name,j,k):\n",
    "            temp_list.append([i[0],m,q,l])\n",
    "pd.DataFrame(temp_list,columns=[\"drugs\",\"cells_line\",\"pridict\",\"origin\"]).sort_values(\"cells_line\").to_csv(\"pcc_cpu_test_multi_cells_line_unite_coum.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd7bb2e-7c9f-45af-99e4-c135c220e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单线程\n",
    "# # 加载保存的数组\n",
    "# lin = np.load(\"lin.npy\")\n",
    "# PCC_mean = 0\n",
    "# res_pcc_list = []\n",
    "# for t_coum in range(2, coum+1, 1):    #邻居\n",
    "#     PCC = 0\n",
    "#     Name_data = []\n",
    "#     a = 1\n",
    "#     for linename in columns:\n",
    "#         #求PCC\n",
    "#         alpha = []\n",
    "#         result_pcc = []\n",
    "#         pcc_split = []\n",
    "#         for alp in lin:\n",
    "#             # r1 = []\n",
    "#             # ct = 0\n",
    "#             pre = []\n",
    "#             for elem in range(39):\n",
    "#                 pp = []\n",
    "#                 for j in TTT[(coum * a - t_coum):(coum * a)]: \n",
    "#                     pp.append(np.exp(-pow(1 - j, 2) / (2 * pow(alp, 2))))#改函数\n",
    "#                 pre.append(np.sum(pp / np.sum(pp) * dict_columns_split[f\"{linename},{elem}\"]['max_x_line'][-t_coum:]))\n",
    "#             pcc_split.append(np.corrcoef(pre, data2[linename])[0, 1])\n",
    "#         result_pcc.append(np.max(pcc_split))\n",
    "#         alpha.append(lin[pcc_split.index(np.max(pcc_split))])\n",
    "#         pcc=result_pcc[0]\n",
    "\n",
    "#         #求MSE\n",
    "#         r1 = []\n",
    "#         ct = 0\n",
    "#         alp = alpha[0]\n",
    "#         for elem in range(39):\n",
    "#             pp = []\n",
    "#             for j in TTT[(coum * a - t_coum):(coum * a)]:\n",
    "#                 pp.append(np.exp(-pow(1 - j, 2) / (2 * pow(alp, 2))))  # 改函数\n",
    "#             r1.append(np.sum((pp/np.sum(pp)) * dict_columns_split[f\"{linename},{elem}\"]['max_x_line'][-t_coum:]) -\n",
    "#                             dict_columns_split[f\"{linename},{elem}\"]['y_line'])\n",
    "#         mse=np.mean(np.square(r1))\n",
    "#         rmse=math.sqrt(mse)\n",
    "#         Name_data.append([linename, t_coum, alp, mse, pcc, rmse])\n",
    "#         a = a+1\n",
    "#     pcc_mean = pd.DataFrame(Name_data, columns=['drug', 'coum', \"alp\", \"mse\", \"pcc\", \"rmse\"])[\"pcc\"].mean()\n",
    "#     if pcc_mean > PCC_mean:\n",
    "#         PCC_mean = pcc_mean\n",
    "#         res_pcc_list = Name_data\n",
    "# pcc_mean = pd.DataFrame(res_pcc_list, columns=['drug', 'coum', \"alp\", \"mse\", \"pcc\", \"rmse\"]).to_csv('pcc_unite.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b218375-32fc-449d-9a06-f1f11648a489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a55294-1d96-4741-af35-25cd1eb6c34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f395d-887d-424d-9541-ef0340390ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
